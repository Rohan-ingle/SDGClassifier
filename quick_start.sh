#!/bin/bash

# SDG Classifier Quick Start Script
# This script demonstrates the basic functionality of the MLOps pipeline

echo "=================================================="
echo "SDG Classifier MLOps Pipeline - Quick Start"
echo "=================================================="

# Set conda environment
export CONDA_ENV="/home/ubuntu/mlops/mlops"

# Check if we're in the right directory
if [ ! -f "params.yaml" ]; then
    echo "Error: Please run this script from the SDGClassifier directory"
    exit 1
fi

echo "1. Checking dependencies..."
conda run -p $CONDA_ENV python -c "
import pandas as pd
import sklearn
import nltk
import dvc
print('âœ“ All core dependencies available')
"

echo "2. Validating dataset..."
conda run -p $CONDA_ENV python -c "
import pandas as pd
try:
    df = pd.read_csv('data/raw/osdg-community-data-v2024-04-01.csv', sep='\t', nrows=100)
    print(f'âœ“ Dataset loaded successfully: {len(df)} sample rows')
    print(f'âœ“ Columns: {list(df.columns)}')
    print(f'âœ“ SDG distribution in sample: {dict(df[\"sdg\"].value_counts().head())}')
except Exception as e:
    print(f'âœ— Dataset validation failed: {e}')
    exit(1)
"

echo "3. Testing data preprocessing..."
conda run -p $CONDA_ENV python -c "
import sys
sys.path.append('src')
from src.data.preprocess import TextPreprocessor
import pandas as pd

# Test text preprocessor
preprocessor = TextPreprocessor(remove_stopwords=True, lowercase=True)
sample_text = 'This research focuses on renewable energy solutions for sustainable development and climate change mitigation.'
cleaned = preprocessor.clean_text(sample_text)
print(f'âœ“ Text preprocessing test successful')
print(f'  Original: {sample_text[:50]}...')
print(f'  Cleaned:  {cleaned[:50]}...')
"

echo "4. Testing model training components..."
conda run -p $CONDA_ENV python -c "
import sys
sys.path.append('src')
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import LabelEncoder
import numpy as np

# Create sample data
texts = ['renewable energy sustainability', 'education quality learning', 'gender equality women'] * 10
labels = [7, 4, 5] * 10

# Test vectorization
vectorizer = TfidfVectorizer(max_features=100)
X = vectorizer.fit_transform(texts)

# Test label encoding
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(labels)

# Test model training
model = RandomForestClassifier(n_estimators=10, random_state=42)
model.fit(X, y)

print(f'âœ“ Model training test successful')
print(f'  Features: {X.shape[1]}')
print(f'  Classes: {len(label_encoder.classes_)}')
print(f'  Accuracy: {model.score(X, y):.4f}')
"

echo "5. Testing DVC pipeline..."
conda run -p $CONDA_ENV dvc dag
echo "âœ“ DVC pipeline structure validated"

echo "6. Running basic tests..."
if conda run -p $CONDA_ENV python -m pytest tests/ -v --tb=short; then
    echo "âœ“ All tests passed"
else
    echo "âš  Some tests failed (this is expected in the initial setup)"
fi

echo ""
echo "=================================================="
echo "Quick Start Completed Successfully! ðŸŽ‰"
echo "=================================================="
echo ""
echo "Next steps:"
echo "1. Run the full pipeline: conda run -p $CONDA_ENV dvc repro"
echo "2. View results: conda run -p $CONDA_ENV dvc metrics show"
echo "3. Explore notebooks: jupyter notebook notebooks/"
echo "4. Check CI/CD: git push to trigger automated pipeline"
echo ""
echo "For more information, see README.md"
echo "=================================================="